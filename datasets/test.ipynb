{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/husainhz7/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/husainhz7/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/husainhz7/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # to transform a given text into a vector on the basis of the frequency (count) of each word that occurs in the entire text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # to transform text into a term and document frequency based representation of numbers\n",
    "import nltk                                                  # platform for building Python programs to process natural language\n",
    "nltk.download('stopwords')                                   # to download the stop words\n",
    "nltk.download('punkt')                                       # tokenizer divides a text into a list of sentences, by using an unsupervised algorithm to build a model for abbreviation words, collocations, and words that start sentences\n",
    "nltk.download('wordnet')                                     # to lemmatize word using WordNet's built-in function\n",
    "from nltk.corpus import stopwords                            # importing the NTLK stopwords to remove articles, preposition and other words that are not actionable\n",
    "from nltk.stem.porter import PorterStemmer                   # process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words\n",
    "from wordcloud import WordCloud                              # visualization of words based on their frequency\n",
    "from nltk.tokenize import word_tokenize                      # allows to create individual objects from a bag of words\n",
    "from bs4 import BeautifulSoup                                # Python library for pulling data from HTML and XML files\n",
    "import re                                                    # regular expression (or RE) specifies a set of strings that matches it\n",
    "from sklearn.naive_bayes import MultinomialNB                # to import multinomial naive bayes which is suitable for classification with discrete features (e.g., word counts for text classification)\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score# to import metrics for evaluating the classification model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(551585, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>main_category</th>\n",
       "      <th>sub_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lloyd 1.5 Ton 3 Star Inverter Split Ac (5 In 1...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>Air Conditioners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LG 1.5 Ton 5 Star AI DUAL Inverter Split AC (C...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>Air Conditioners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LG 1 Ton 4 Star Ai Dual Inverter Split Ac (Cop...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>Air Conditioners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LG 1.5 Ton 3 Star AI DUAL Inverter Split AC (C...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>Air Conditioners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carrier 1.5 Ton 3 Star Inverter Split AC (Copp...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>Air Conditioners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Voltas 1.4 Ton 3 Star Inverter Split AC(Copper...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>Air Conditioners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lloyd 1.0 Ton 3 Star Inverter Split Ac (5 In 1...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>Air Conditioners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lloyd 1.5 Ton 5 Star Inverter Split Ac (5 In 1...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>Air Conditioners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Carrier 1 Ton 3 Star AI Flexicool Inverter Spl...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>Air Conditioners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Voltas 1.5 Ton, 5 Star, Inverter Split AC(Copp...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>Air Conditioners</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name main_category   \n",
       "0  Lloyd 1.5 Ton 3 Star Inverter Split Ac (5 In 1...    appliances  \\\n",
       "1  LG 1.5 Ton 5 Star AI DUAL Inverter Split AC (C...    appliances   \n",
       "2  LG 1 Ton 4 Star Ai Dual Inverter Split Ac (Cop...    appliances   \n",
       "3  LG 1.5 Ton 3 Star AI DUAL Inverter Split AC (C...    appliances   \n",
       "4  Carrier 1.5 Ton 3 Star Inverter Split AC (Copp...    appliances   \n",
       "5  Voltas 1.4 Ton 3 Star Inverter Split AC(Copper...    appliances   \n",
       "6  Lloyd 1.0 Ton 3 Star Inverter Split Ac (5 In 1...    appliances   \n",
       "7  Lloyd 1.5 Ton 5 Star Inverter Split Ac (5 In 1...    appliances   \n",
       "8  Carrier 1 Ton 3 Star AI Flexicool Inverter Spl...    appliances   \n",
       "9  Voltas 1.5 Ton, 5 Star, Inverter Split AC(Copp...    appliances   \n",
       "\n",
       "       sub_category  \n",
       "0  Air Conditioners  \n",
       "1  Air Conditioners  \n",
       "2  Air Conditioners  \n",
       "3  Air Conditioners  \n",
       "4  Air Conditioners  \n",
       "5  Air Conditioners  \n",
       "6  Air Conditioners  \n",
       "7  Air Conditioners  \n",
       "8  Air Conditioners  \n",
       "9  Air Conditioners  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Amazon-Products.csv')\n",
    "print(df.shape)\n",
    "\n",
    "# remove uneeded\n",
    "# df.drop(labels=['image', 'link', 'ratings', 'no_of_ratings', 'discount_price', 'actual_price'], axis=1, inplace=True)\n",
    "df = df[df.columns[1:3]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main_category\n",
       "accessories                116141\n",
       "men's clothing              76656\n",
       "women's clothing            76512\n",
       "tv, audio & cameras         68659\n",
       "men's shoes                 57456\n",
       "appliances                  33096\n",
       "stores                      32903\n",
       "home & kitchen              14568\n",
       "kids' fashion               13488\n",
       "sports & fitness            12648\n",
       "bags & luggage              10416\n",
       "beauty & health             10122\n",
       "car & motorbike              7080\n",
       "toys & baby products         6216\n",
       "women's shoes                5472\n",
       "industrial supplies          4104\n",
       "grocery & gourmet foods      3312\n",
       "pet supplies                 1632\n",
       "music                        1080\n",
       "home, kitchen, pets            24\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.main_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    pattern = r'[^a-zA-Z0-9\\s]'\n",
    "    text = re.sub(pattern,'',text)\n",
    "    return text\n",
    "\n",
    "def remove_between_paranthesis(text):\n",
    "    return re.sub('\\([^])*\\]', '', text)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
